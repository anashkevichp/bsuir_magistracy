\section[Задача Коши]
{ЗАДАЧА КОШИ}

\subsection{Формулировка задачи Коши}

Решением задачи Коши является отыскание функции $y = y(x)$,
для которой выполняются определенные начальные условия.
Формально, задачу Коши в математических терминах можно записать
следующим образом.
$$
    y'(x) = f(x, y), \hspace{1cm} y (a) = y_0, \hspace{1cm} x \in [a, b].
$$

Достаточно часто задача Коши обычно возникает при анализе процессов,
определяемых дифференциальным законом эволюции и начальным состоянием
(математическим выражением которых и являются уравнение и начальное условие).
Этим объясняется частое употребление символа $t$ вместо $x$, а также этим мотивируется
терминология и выбор обозначений: начальные данные задаются при $t = 0$,
а решение отыскивается при $t > 0$~\cite{numerical_intro, numerical_volkov}.


\subsection{Классификация методов решения задачи Коши}

Можно выделить две группы методов решения задачи Коши. Рассмотрим эти
группы подробнее.


\subsubsection{Одношаговые методы}

Одношаговыми методами решения задачи Коши называются те методы, которые для
нахождения $y_{i+1}$ используют только значение $y_i$, то есть любой одношаговый
метод в общем смысле имеет вид:
$$
    y_{k+1} = y_k + h\Phi(t_k, y_k),
$$
где $\Phi$ -- некоторая функция, называемая \textit{функцией приращения}, \\
$h$ -- произвольная длинна шага.

К одношаговым методам решения задачи Коши относятся: метод Эйлера, Адамса, Гюна, Тейлора,
методы Рунге-Кутта и др. Приведём общую характеристику этих методов:
\begin{enumerate}
  \item В основе методов лежит разложение функций в ряд Тейлора.
  \item Для получения информации в новой точке, нужно иметь данные лишь в одной
    предыдущей точке. Это свойство принято называть свойством <<самостартования>>.
    Следствие -- относительная простота программной реализации.
  \item Свойство <<самостартования>> позволяет гибко управлять шагом $h$~\cite{numerical_matlab}.
\end{enumerate}

\subsubsection{Многошаговые методы}

Для того, чтобы повысить точность и вычислить дальнейшие производные искомой
функции, необходимо знать её значение в большем количестве точек. В одношаговых
методах для вычисления $y^{(n)}_{i+1}$ использовалось $(n-1)$ дополнительных точек
на интервале $x_i, x_{i+1}$. В \textit{многошаговых} методах для этого используются
результаты счета на предыдущих шагах -- в точках $x_i$, $x_{i-1}$, $x_{i-2}, \dots$.
Поэтому для старта метода предварительно необходимо вычислить значения $y$ в
достаточном количестве первых точек (с помощью одношаговых) методов.

Для вывода формул используются различные приближенные решения приведенного
интегрального уравнения
$$
  y_{i+k} = y_{i-p} + \int_{x_{i-p}}^{x_{i+k}} f(x,y)dx.
$$

Стоит упомянуть об ещё одной группе методов решения задачи Коши~-- методы
\textit{прогноза и коррекции} (или предиктор-корректор, англ.~predictor-corrector methods) ---
семейство алгоритмов численного решения различных задач, которые состоят
из двух шагов. На первом шаге (прогноз) вычисляется грубое приближение
требуемой величины. На втором шаге при помощи иного метода приближение
уточняется (корректируется)~\cite{approx_intro}.

К многошаговым методам, а также группе методов предиктор-корректор можно отнести
метод Милна, Адамса-Башфорта, а также Хемминга. В разделе 2 данной работы подробнее
рассмотрим метод Хемминга.

\pagebreak
